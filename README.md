# Movies-ETL
Challenge 8 for UT Bootcamp

The scenario for Module 8 is that we are assembling datasets that will be used for a hackathon competition. The original data files consist of movie information from Wikipedia, from an IMDb set on Kaggle, and ratings data from MovieLens. 

# Purpose
The purpose of this homework challenge was to experience various parts of the ETL (Extract, Transform, Load) data pipeline process. The vast majority of the files were directed towards the Transform part of the process.

The Jupyter Notebook files build on each other, with each one being a subset of the next one.
1. ETL_function_test.ipynb
2. ETL_clean_wiki_movies.ipynb
3. ETL_clean_kaggle_data.ipynb
4. ETL_create_database.ipynb

I was supposed to get 6,052 rows for the movies table, but I have 9,686.  I'm not sure where the error was in importing for the movies table.